# Data Investigation Platform - Documentation

## What Is This?

A personal data analysis tool I'm building to make my life easier when working with random CSV files and datasets. Drop files, ask questions in plain English, get answers with visualizations. 

**This is NOT a commercial product** - it's an open-source tool I'm building for myself and sharing with anyone who finds it useful.

## Documentation Structure

### üìã [MVP_OVERVIEW.md](MVP_OVERVIEW.md)
High-level overview of what I'm building and why. Start here to understand the vision.

### üèóÔ∏è [PROJECT_ARCHITECTURE.md](PROJECT_ARCHITECTURE.md)
Technical architecture and system design. How all the pieces fit together.

### ‚ú® [FEATURE_SPECIFICATIONS.md](FEATURE_SPECIFICATIONS.md)
Detailed feature list with priorities. What's in the MVP vs. future nice-to-haves.

### üîß [TECHNICAL_IMPLEMENTATION.md](TECHNICAL_IMPLEMENTATION.md)
Step-by-step implementation guide. Actual code structure and development plan.

### üé® [UI_UX_DESIGN.md](UI_UX_DESIGN.md)
UI mockups and interaction patterns. What it will look like and how it will work.

## Quick Summary

### The Problem
I'm tired of:
- Writing SQL for every little data question
- Juggling multiple CSV files without knowing how they connect
- Using complex BI tools for simple data exploration
- Losing track of useful queries I've written

### The Solution
A tool where I can:
1. Drop any CSV/Parquet files
2. Ask questions in plain English
3. Get SQL generated by local LLM
4. See smart visualizations
5. Export everything as HTML/Jupyter

### Key Features (MVP)
- **Project-based organization** - Keep different datasets separate
- **Multi-file intelligence** - Auto-detect relationships between files
- **LLM-powered SQL** - Natural language to SQL (already working!)
- **Smart profiling** - Instant stats and insights on file drop
- **Export suite** - HTML, Jupyter notebooks, SQL scripts

### Tech Stack
- Python + Streamlit (keep it simple)
- DuckDB (fast local SQL engine)
- Local LLM via LM Studio
- Plotly for visualizations

## Development Timeline

### Week 1-2: Foundation
- Project management system
- File upload with profiling
- Integrate with existing SQL generator

### Week 3-4: Intelligence
- Relationship detection
- Query history
- Session recording

### Week 5-6: Polish
- Visualizations
- Export system
- UI improvements

## Why Open Source?

I'm building this for myself, but if others find it useful, great! Feel free to:
- Use it for your own data analysis
- Fork it and modify for your needs
- Contribute improvements back
- Share your own analysis templates

## Not Goals

This tool is NOT trying to be:
- A commercial BI platform
- A multi-user collaboration tool  
- A cloud service
- A data warehouse
- The next Tableau/PowerBI

It's just a personal tool for quick data investigation.

## Getting Started (Once Built)

```bash
# Clone the repo
git clone https://github.com/[username]/data-investigation-platform

# Install dependencies
poetry install

# Run it
streamlit run app.py

# Start analyzing data!
```

## Current Status

üöß **In Design Phase** - These documents represent the plan. Implementation starts next week.

## Questions or Ideas?

This is a personal project, but if you have ideas or want to contribute, feel free to open an issue on GitHub!