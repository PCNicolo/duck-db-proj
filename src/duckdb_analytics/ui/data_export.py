"""Data export system with multiple format support."""

import io
import json
from datetime import datetime
from typing import Any, Dict

import pandas as pd
import streamlit as st
from openpyxl.styles import Alignment, Border, Font, PatternFill, Side


class DataExporter:
    """Comprehensive data export system."""

    def __init__(self):
        """Initialize data exporter."""
        self.supported_formats = ["csv", "excel", "json", "parquet", "feather", "sql"]
        self.background_exports = {}

        # Initialize session state
        if "export_history" not in st.session_state:
            st.session_state.export_history = []
        if "export_preferences" not in st.session_state:
            st.session_state.export_preferences = {
                "csv": {"delimiter": ",", "quote_char": '"', "include_header": True},
                "excel": {
                    "sheet_name": "Data Export",
                    "include_header": True,
                    "freeze_panes": True,
                },
                "json": {"format": "records", "pretty_print": True, "indent": 2},
            }

    def render_export_interface(
        self, df: pd.DataFrame, title: str = "Data Export"
    ) -> None:
        """
        Render the data export interface.

        Args:
            df: DataFrame to export
            title: Title for the export interface
        """
        st.subheader(f"ðŸ“¥ {title}")

        if df is None or df.empty:
            st.warning("No data available for export")
            return

        # Export overview
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Rows to Export", f"{len(df):,}")
        with col2:
            st.metric("Columns", f"{len(df.columns):,}")
        with col3:
            memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
            st.metric("Memory Usage", f"{memory_usage:.2f} MB")

        # Format selection
        export_format = st.selectbox(
            "Export Format",
            self.supported_formats,
            format_func=lambda x: {
                "csv": "ðŸ“„ CSV - Comma Separated Values",
                "excel": "ðŸ“Š Excel - Microsoft Excel Format",
                "json": "ðŸ“‹ JSON - JavaScript Object Notation",
                "parquet": "ðŸ—ƒï¸ Parquet - Columnar Storage",
                "feather": "ðŸª¶ Feather - Fast Binary Format",
                "sql": "ðŸ—„ï¸ SQL - INSERT Statements",
            }.get(x, x),
        )

        # Format-specific options
        export_options = self._render_format_options(export_format, df)

        # Data filtering options
        export_data_config = self._render_data_options(df)

        # Export execution
        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ðŸ“¥ Export Now", type="primary"):
                self._execute_export(
                    df, export_format, export_options, export_data_config, title
                )

        with col2:
            if len(df) > 10000:
                if st.button("â³ Background Export"):
                    self._start_background_export(
                        df, export_format, export_options, export_data_config, title
                    )

        with col3:
            if st.button("ðŸ“‹ Preview Export"):
                self._preview_export(
                    df, export_format, export_options, export_data_config
                )

        # Export history and management
        self._render_export_history()
        self._render_background_exports_status()

    def _render_format_options(
        self, format_type: str, df: pd.DataFrame
    ) -> Dict[str, Any]:
        """Render format-specific export options."""
        options = {}

        with st.expander("âš™ï¸ Export Options", expanded=True):
            if format_type == "csv":
                options.update(self._render_csv_options())
            elif format_type == "excel":
                options.update(self._render_excel_options())
            elif format_type == "json":
                options.update(self._render_json_options())
            elif format_type == "parquet":
                options.update(self._render_parquet_options())
            elif format_type == "feather":
                options.update(self._render_feather_options())
            elif format_type == "sql":
                options.update(self._render_sql_options())

        return options

    def _render_csv_options(self) -> Dict[str, Any]:
        """Render CSV export options."""
        col1, col2, col3 = st.columns(3)

        with col1:
            delimiter = st.selectbox(
                "Delimiter",
                [",", ";", "|", "\t"],
                index=[",", ";", "|", "\t"].index(
                    st.session_state.export_preferences["csv"]["delimiter"]
                ),
                format_func=lambda x: {"\\t": "Tab"}.get(x, x),
            )

        with col2:
            quote_char = st.selectbox(
                "Quote Character",
                ['"', "'", "none"],
                index=['"', "'", "none"].index(
                    st.session_state.export_preferences["csv"]["quote_char"]
                ),
            )

        with col3:
            line_terminator = st.selectbox(
                "Line Terminator",
                ["\n", "\r\n"],
                format_func=lambda x: {
                    "\\n": "LF (Unix)",
                    "\\r\\n": "CRLF (Windows)",
                }.get(x, x),
            )

        col1, col2, col3 = st.columns(3)

        with col1:
            include_header = st.checkbox(
                "Include Header",
                value=st.session_state.export_preferences["csv"]["include_header"],
            )

        with col2:
            include_index = st.checkbox("Include Index", value=False)

        with col3:
            encoding = st.selectbox(
                "Encoding", ["utf-8", "latin-1", "ascii", "utf-16"], index=0
            )

        # Update preferences
        st.session_state.export_preferences["csv"] = {
            "delimiter": delimiter,
            "quote_char": quote_char,
            "include_header": include_header,
        }

        return {
            "sep": delimiter,
            "quotechar": quote_char if quote_char != "none" else None,
            "lineterminator": line_terminator,
            "header": include_header,
            "index": include_index,
            "encoding": encoding,
        }

    def _render_excel_options(self) -> Dict[str, Any]:
        """Render Excel export options."""
        col1, col2, col3 = st.columns(3)

        with col1:
            sheet_name = st.text_input(
                "Sheet Name",
                value=st.session_state.export_preferences["excel"]["sheet_name"],
            )

        with col2:
            include_header = st.checkbox(
                "Include Header",
                value=st.session_state.export_preferences["excel"]["include_header"],
            )

        with col3:
            include_index = st.checkbox("Include Index", value=False)

        col1, col2, col3 = st.columns(3)

        with col1:
            freeze_panes = st.checkbox(
                "Freeze Header Row",
                value=st.session_state.export_preferences["excel"]["freeze_panes"],
            )

        with col2:
            auto_column_width = st.checkbox("Auto-size Columns", value=True)

        with col3:
            apply_formatting = st.checkbox("Apply Cell Formatting", value=True)

        # Multiple sheets option
        multiple_sheets = st.checkbox("Split into Multiple Sheets", value=False)
        rows_per_sheet = None
        if multiple_sheets:
            rows_per_sheet = st.number_input(
                "Rows per Sheet",
                min_value=1000,
                max_value=1048576,  # Excel row limit
                value=50000,
                step=1000,
            )

        # Update preferences
        st.session_state.export_preferences["excel"] = {
            "sheet_name": sheet_name,
            "include_header": include_header,
            "freeze_panes": freeze_panes,
        }

        return {
            "sheet_name": sheet_name,
            "header": include_header,
            "index": include_index,
            "freeze_panes": freeze_panes,
            "auto_column_width": auto_column_width,
            "apply_formatting": apply_formatting,
            "multiple_sheets": multiple_sheets,
            "rows_per_sheet": rows_per_sheet,
        }

    def _render_json_options(self) -> Dict[str, Any]:
        """Render JSON export options."""
        col1, col2, col3 = st.columns(3)

        with col1:
            format_type = st.selectbox(
                "JSON Format",
                ["records", "columns", "values", "table"],
                index=["records", "columns", "values", "table"].index(
                    st.session_state.export_preferences["json"]["format"]
                ),
                help="records: [{col1: val1, col2: val2}, ...], columns: {col1: [val1, val2, ...], col2: [...]}",
            )

        with col2:
            pretty_print = st.checkbox(
                "Pretty Print",
                value=st.session_state.export_preferences["json"]["pretty_print"],
            )

        with col3:
            if pretty_print:
                indent = st.number_input(
                    "Indentation",
                    min_value=1,
                    max_value=8,
                    value=st.session_state.export_preferences["json"]["indent"],
                )
            else:
                indent = None

        col1, col2 = st.columns(2)

        with col1:
            ensure_ascii = st.checkbox("Ensure ASCII", value=False)

        with col2:
            include_dtypes = st.checkbox("Include Data Types", value=False)

        # Update preferences
        st.session_state.export_preferences["json"] = {
            "format": format_type,
            "pretty_print": pretty_print,
            "indent": indent or 2,
        }

        return {
            "orient": format_type,
            "indent": indent,
            "ensure_ascii": ensure_ascii,
            "include_dtypes": include_dtypes,
        }

    def _render_parquet_options(self) -> Dict[str, Any]:
        """Render Parquet export options."""
        col1, col2, col3 = st.columns(3)

        with col1:
            compression = st.selectbox(
                "Compression", ["snappy", "gzip", "brotli", "lz4", "none"], index=0
            )

        with col2:
            include_index = st.checkbox("Include Index", value=False)

        with col3:
            row_group_size = st.number_input(
                "Row Group Size",
                min_value=1000,
                max_value=100000,
                value=50000,
                step=1000,
            )

        return {
            "compression": compression if compression != "none" else None,
            "index": include_index,
            "row_group_size": row_group_size,
        }

    def _render_feather_options(self) -> Dict[str, Any]:
        """Render Feather export options."""
        col1, col2 = st.columns(2)

        with col1:
            compression = st.selectbox(
                "Compression", ["uncompressed", "zstd", "lz4"], index=1
            )

        with col2:
            compression_level = None
            if compression in ["zstd", "lz4"]:
                compression_level = st.slider(
                    "Compression Level", min_value=1, max_value=9, value=3
                )

        return {
            "compression": compression if compression != "uncompressed" else None,
            "compression_level": compression_level,
        }

    def _render_sql_options(self) -> Dict[str, Any]:
        """Render SQL export options."""
        col1, col2, col3 = st.columns(3)

        with col1:
            table_name = st.text_input("Table Name", value="exported_data")

        with col2:
            batch_size = st.number_input(
                "Batch Size", min_value=100, max_value=10000, value=1000, step=100
            )

        with col3:
            include_create_table = st.checkbox("Include CREATE TABLE", value=True)

        col1, col2 = st.columns(2)

        with col1:
            if_exists = st.selectbox(
                "If Table Exists", ["append", "replace", "fail"], index=0
            )

        with col2:
            quote_identifiers = st.checkbox("Quote Identifiers", value=True)

        return {
            "table_name": table_name,
            "batch_size": batch_size,
            "include_create_table": include_create_table,
            "if_exists": if_exists,
            "quote_identifiers": quote_identifiers,
        }

    def _render_data_options(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Render data filtering and sampling options."""
        with st.expander("ðŸ” Data Options", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                export_scope = st.radio(
                    "Export Scope",
                    ["All Data", "Current Filter", "Sample", "Date Range"],
                    help="Choose what subset of data to export",
                )

            with col2:
                if export_scope == "Sample":
                    sample_size = st.number_input(
                        "Sample Size",
                        min_value=100,
                        max_value=len(df),
                        value=min(10000, len(df)),
                        step=100,
                    )
                    sample_method = st.selectbox(
                        "Sample Method", ["Random", "First N", "Last N", "Every Nth"]
                    )
                elif export_scope == "Date Range":
                    # Only show if there are datetime columns
                    datetime_cols = df.select_dtypes(
                        include=["datetime64"]
                    ).columns.tolist()
                    if datetime_cols:
                        date_column = st.selectbox("Date Column", datetime_cols)
                        col1_date, col2_date = st.columns(2)
                        with col1_date:
                            start_date = st.date_input("Start Date")
                        with col2_date:
                            end_date = st.date_input("End Date")
                    else:
                        st.warning("No datetime columns found for date range filtering")
                        export_scope = "All Data"

            # Column selection
            st.subheader("Column Selection")
            col1, col2 = st.columns(2)

            with col1:
                column_mode = st.radio(
                    "Columns to Export",
                    ["All Columns", "Selected Columns", "Exclude Columns"],
                )

            with col2:
                if column_mode in ["Selected Columns", "Exclude Columns"]:
                    selected_columns = st.multiselect(
                        "Choose Columns",
                        df.columns.tolist(),
                        default=(
                            df.columns.tolist()
                            if column_mode == "Selected Columns"
                            else []
                        ),
                    )
                else:
                    selected_columns = df.columns.tolist()

        config = {
            "export_scope": export_scope,
            "column_mode": column_mode,
            "selected_columns": selected_columns,
        }

        # Add scope-specific options
        if export_scope == "Sample":
            config.update({"sample_size": sample_size, "sample_method": sample_method})
        elif export_scope == "Date Range" and datetime_cols:
            config.update(
                {
                    "date_column": date_column,
                    "start_date": start_date,
                    "end_date": end_date,
                }
            )

        return config

    def _execute_export(
        self,
        df: pd.DataFrame,
        format_type: str,
        format_options: Dict,
        data_config: Dict,
        title: str,
    ):
        """Execute the data export."""
        try:
            # Apply data filtering
            filtered_df = self._apply_data_filters(df, data_config)

            if filtered_df.empty:
                st.warning("No data to export after applying filters")
                return

            # Generate filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{title.replace(' ', '_').lower()}_{timestamp}.{format_type}"

            # Export data
            export_data, mime_type = self._export_to_format(
                filtered_df, format_type, format_options
            )

            if export_data:
                # Create download button
                st.download_button(
                    label=f"ðŸ“¥ Download {format_type.upper()}",
                    data=export_data,
                    file_name=filename,
                    mime=mime_type,
                    key=f"download_{timestamp}",
                )

                # Add to export history
                self._add_to_export_history(
                    filename, format_type, len(filtered_df), format_options
                )

                st.success(
                    f"âœ… Export ready! {len(filtered_df):,} rows exported to {format_type.upper()}"
                )

        except Exception as e:
            st.error(f"âŒ Export failed: {str(e)}")

    def _preview_export(
        self,
        df: pd.DataFrame,
        format_type: str,
        format_options: Dict,
        data_config: Dict,
    ):
        """Preview the export data and format."""
        try:
            # Apply data filtering
            filtered_df = self._apply_data_filters(df, data_config)

            if filtered_df.empty:
                st.warning("No data to preview after applying filters")
                return

            st.subheader("ðŸ” Export Preview")

            # Show data preview
            preview_rows = min(100, len(filtered_df))
            st.write(
                f"Preview of first {preview_rows} rows ({len(filtered_df):,} total rows will be exported)"
            )
            st.dataframe(filtered_df.head(preview_rows), use_container_width=True)

            # Show format preview
            if format_type in ["csv", "json", "sql"]:
                st.subheader(f"ðŸ“„ {format_type.upper()} Format Preview")
                sample_data = filtered_df.head(5)

                if format_type == "csv":
                    csv_preview = sample_data.to_csv(
                        index=format_options.get("index", False),
                        **{
                            k: v
                            for k, v in format_options.items()
                            if k in ["sep", "quotechar", "header", "encoding"]
                        },
                    )
                    st.code(csv_preview, language="text")

                elif format_type == "json":
                    json_preview = sample_data.to_json(
                        **{
                            k: v
                            for k, v in format_options.items()
                            if k in ["orient", "indent", "ensure_ascii"]
                        }
                    )
                    st.code(json_preview, language="json")

                elif format_type == "sql":
                    # Generate sample INSERT statements
                    sql_preview = self._generate_sql_preview(
                        sample_data, format_options
                    )
                    st.code(sql_preview, language="sql")

        except Exception as e:
            st.error(f"âŒ Preview failed: {str(e)}")

    def _apply_data_filters(self, df: pd.DataFrame, data_config: Dict) -> pd.DataFrame:
        """Apply data filtering based on configuration."""
        filtered_df = df.copy()

        # Apply scope filtering
        export_scope = data_config.get("export_scope", "All Data")

        if export_scope == "Sample":
            sample_size = data_config.get("sample_size", 1000)
            sample_method = data_config.get("sample_method", "Random")

            if sample_method == "Random":
                filtered_df = filtered_df.sample(min(sample_size, len(filtered_df)))
            elif sample_method == "First N":
                filtered_df = filtered_df.head(sample_size)
            elif sample_method == "Last N":
                filtered_df = filtered_df.tail(sample_size)
            elif sample_method == "Every Nth":
                step = max(1, len(filtered_df) // sample_size)
                filtered_df = filtered_df.iloc[::step]

        elif export_scope == "Date Range":
            date_column = data_config.get("date_column")
            start_date = data_config.get("start_date")
            end_date = data_config.get("end_date")

            if (
                all([date_column, start_date, end_date])
                and date_column in filtered_df.columns
            ):
                filtered_df[date_column] = pd.to_datetime(filtered_df[date_column])
                mask = (filtered_df[date_column].dt.date >= start_date) & (
                    filtered_df[date_column].dt.date <= end_date
                )
                filtered_df = filtered_df[mask]

        # Apply column filtering
        column_mode = data_config.get("column_mode", "All Columns")
        selected_columns = data_config.get(
            "selected_columns", filtered_df.columns.tolist()
        )

        if column_mode == "Selected Columns":
            available_columns = [
                col for col in selected_columns if col in filtered_df.columns
            ]
            if available_columns:
                filtered_df = filtered_df[available_columns]
        elif column_mode == "Exclude Columns":
            columns_to_keep = [
                col for col in filtered_df.columns if col not in selected_columns
            ]
            if columns_to_keep:
                filtered_df = filtered_df[columns_to_keep]

        return filtered_df

    def _export_to_format(
        self, df: pd.DataFrame, format_type: str, options: Dict
    ) -> tuple:
        """Export DataFrame to specified format."""
        if format_type == "csv":
            output = io.StringIO()
            df.to_csv(output, **options)
            return output.getvalue().encode("utf-8"), "text/csv"

        elif format_type == "excel":
            return (
                self._export_to_excel(df, options),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

        elif format_type == "json":
            json_str = df.to_json(
                **{k: v for k, v in options.items() if k != "include_dtypes"}
            )

            if options.get("include_dtypes"):
                data = {
                    "data": json.loads(json_str),
                    "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
                }
                json_str = json.dumps(data, indent=options.get("indent"))

            return json_str.encode("utf-8"), "application/json"

        elif format_type == "parquet":
            output = io.BytesIO()
            df.to_parquet(output, **options)
            return output.getvalue(), "application/octet-stream"

        elif format_type == "feather":
            output = io.BytesIO()
            df.to_feather(output, **{k: v for k, v in options.items() if v is not None})
            return output.getvalue(), "application/octet-stream"

        elif format_type == "sql":
            sql_statements = self._generate_sql_statements(df, options)
            return sql_statements.encode("utf-8"), "text/plain"

        else:
            raise ValueError(f"Unsupported format: {format_type}")

    def _export_to_excel(self, df: pd.DataFrame, options: Dict) -> bytes:
        """Export DataFrame to Excel with advanced formatting."""
        output = io.BytesIO()

        if options.get("multiple_sheets") and options.get("rows_per_sheet"):
            # Multiple sheets export
            with pd.ExcelWriter(output, engine="openpyxl") as writer:
                rows_per_sheet = options["rows_per_sheet"]
                num_sheets = (len(df) - 1) // rows_per_sheet + 1

                for i in range(num_sheets):
                    start_row = i * rows_per_sheet
                    end_row = min((i + 1) * rows_per_sheet, len(df))
                    sheet_df = df.iloc[start_row:end_row]

                    sheet_name = f"{options['sheet_name']}_{i+1}"
                    sheet_df.to_excel(
                        writer,
                        sheet_name=sheet_name,
                        index=options.get("index", False),
                        header=options.get("header", True),
                    )

                    # Apply formatting if requested
                    if options.get("apply_formatting"):
                        self._apply_excel_formatting(
                            writer.sheets[sheet_name], sheet_df, options
                        )
        else:
            # Single sheet export
            with pd.ExcelWriter(output, engine="openpyxl") as writer:
                df.to_excel(
                    writer,
                    sheet_name=options["sheet_name"],
                    index=options.get("index", False),
                    header=options.get("header", True),
                )

                # Apply formatting if requested
                if options.get("apply_formatting"):
                    self._apply_excel_formatting(
                        writer.sheets[options["sheet_name"]], df, options
                    )

        return output.getvalue()

    def _apply_excel_formatting(self, worksheet, df: pd.DataFrame, options: Dict):
        """Apply formatting to Excel worksheet."""
        # Header formatting
        if options.get("header", True):
            header_fill = PatternFill(
                start_color="366092", end_color="366092", fill_type="solid"
            )
            header_font = Font(color="FFFFFF", bold=True)

            for col in range(1, len(df.columns) + 1):
                cell = worksheet.cell(row=1, column=col)
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal="center", vertical="center")

        # Auto-size columns
        if options.get("auto_column_width"):
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)  # Cap at 50 characters
                worksheet.column_dimensions[column_letter].width = adjusted_width

        # Freeze panes
        if options.get("freeze_panes") and options.get("header", True):
            worksheet.freeze_panes = "A2"

        # Add borders
        thin_border = Border(
            left=Side(style="thin"),
            right=Side(style="thin"),
            top=Side(style="thin"),
            bottom=Side(style="thin"),
        )

        for row in worksheet.iter_rows(
            min_row=1, max_row=len(df) + 1, min_col=1, max_col=len(df.columns)
        ):
            for cell in row:
                cell.border = thin_border

    def _generate_sql_statements(self, df: pd.DataFrame, options: Dict) -> str:
        """Generate SQL INSERT statements."""
        table_name = options.get("table_name", "exported_data")
        batch_size = options.get("batch_size", 1000)
        include_create_table = options.get("include_create_table", True)
        quote_identifiers = options.get("quote_identifiers", True)

        statements = []

        # CREATE TABLE statement
        if include_create_table:
            create_table = self._generate_create_table_statement(
                df, table_name, quote_identifiers
            )
            statements.append(create_table)

        # INSERT statements
        quote = '"' if quote_identifiers else ""
        columns = [f"{quote}{col}{quote}" for col in df.columns]
        columns_str = ", ".join(columns)

        # Process data in batches
        for i in range(0, len(df), batch_size):
            batch_df = df.iloc[i : i + batch_size]
            values_list = []

            for _, row in batch_df.iterrows():
                values = []
                for val in row:
                    if pd.isna(val):
                        values.append("NULL")
                    elif isinstance(val, str):
                        escaped_val = val.replace("'", "''")
                        values.append(f"'{escaped_val}'")
                    elif isinstance(val, (int, float)):
                        values.append(str(val))
                    else:
                        values.append(f"'{str(val)}'")
                values_list.append(f"({', '.join(values)})")

            if values_list:
                insert_stmt = (
                    f"INSERT INTO {quote}{table_name}{quote} ({columns_str}) VALUES\n"
                )
                insert_stmt += ",\n".join(values_list) + ";"
                statements.append(insert_stmt)

        return "\n\n".join(statements)

    def _generate_create_table_statement(
        self, df: pd.DataFrame, table_name: str, quote_identifiers: bool
    ) -> str:
        """Generate CREATE TABLE statement based on DataFrame dtypes."""
        quote = '"' if quote_identifiers else ""

        column_definitions = []
        for col, dtype in df.dtypes.items():
            col_name = f"{quote}{col}{quote}"

            if pd.api.types.is_integer_dtype(dtype):
                sql_type = "INTEGER"
            elif pd.api.types.is_float_dtype(dtype):
                sql_type = "REAL"
            elif pd.api.types.is_bool_dtype(dtype):
                sql_type = "BOOLEAN"
            elif pd.api.types.is_datetime64_any_dtype(dtype):
                sql_type = "TIMESTAMP"
            else:
                sql_type = "TEXT"

            column_definitions.append(f"{col_name} {sql_type}")

        return (
            f"CREATE TABLE {quote}{table_name}{quote} (\n    "
            + ",\n    ".join(column_definitions)
            + "\n);"
        )

    def _generate_sql_preview(self, df: pd.DataFrame, options: Dict) -> str:
        """Generate a preview of SQL statements."""
        preview_df = df.head(3)  # Just show 3 rows for preview
        return self._generate_sql_statements(preview_df, options)

    def _start_background_export(
        self,
        df: pd.DataFrame,
        format_type: str,
        format_options: Dict,
        data_config: Dict,
        title: str,
    ):
        """Start a background export for large datasets."""
        export_id = datetime.now().strftime("%Y%m%d_%H%M%S_%f")

        self.background_exports[export_id] = {
            "status": "starting",
            "progress": 0,
            "format": format_type,
            "rows": len(df),
            "start_time": datetime.now(),
            "title": title,
        }

        st.info(f"ðŸš€ Background export started (ID: {export_id})")

        # This would typically be run in a separate thread or async task
        # For now, we'll simulate it
        self.background_exports[export_id]["status"] = "queued"
        st.info("Export added to queue. Check status below.")

    def _render_export_history(self):
        """Render export history."""
        if st.session_state.export_history:
            with st.expander("ðŸ“ˆ Export History"):
                for export_record in reversed(
                    st.session_state.export_history[-10:]
                ):  # Show last 10
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.write(f"**{export_record['filename']}**")
                    with col2:
                        st.write(f"{export_record['format'].upper()}")
                    with col3:
                        st.write(f"{export_record['rows']:,} rows")
                    with col4:
                        st.write(export_record["timestamp"])

    def _render_background_exports_status(self):
        """Render status of background exports."""
        if self.background_exports:
            with st.expander("â³ Background Exports Status"):
                for export_id, export_info in self.background_exports.items():
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.write(f"**{export_info['title']}**")
                    with col2:
                        status_emoji = {
                            "starting": "ðŸš€",
                            "queued": "â³",
                            "processing": "âš™ï¸",
                            "completed": "âœ…",
                            "failed": "âŒ",
                        }
                        st.write(
                            f"{status_emoji.get(export_info['status'])} {export_info['status'].title()}"
                        )
                    with col3:
                        st.write(f"{export_info['rows']:,} rows")
                    with col4:
                        elapsed = datetime.now() - export_info["start_time"]
                        st.write(f"{elapsed.total_seconds():.0f}s")

    def _add_to_export_history(
        self, filename: str, format_type: str, row_count: int, options: Dict
    ):
        """Add export to history."""
        export_record = {
            "filename": filename,
            "format": format_type,
            "rows": row_count,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "options": options,
        }

        st.session_state.export_history.append(export_record)

        # Keep only last 50 exports
        if len(st.session_state.export_history) > 50:
            st.session_state.export_history = st.session_state.export_history[-50:]
